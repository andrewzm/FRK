\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage[margin=1in]{geometry}

\usepackage{siunitx} % si units

% ---- Math mode commands ----

\usepackage{rotating} % \rotatebox

\usepackage{amsmath}	% align environment.
\usepackage{amsfonts}	% \mathbb{} (used for Real number symbol, etc.)
\usepackage{amsthm}		% mathy stuff (Theorems, Lemmas, etc.)
\usepackage{commath}
\usepackage{bbm} % \mathbb{} doesn't support digits (1, 2, 3, etc.), so use \mathbbm{} in these instances
\usepackage{mathtools} % \vdotswithin command to have vertical dots between equals signs

%% Lists
\usepackage{enumerate}

%% Formatting tables
\usepackage{pbox} % formatting cells with a table (forced line break within a cell)
\usepackage{multirow}
\newenvironment{tabnote}{\par\footnotesize}{\par}

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% Nice boldface math
\def\mbf#1{{%         \mbf{X} makes X a math bold letter
\mathchoice%          selects with respect to current style
{\hbox{\boldmath$\displaystyle{#1}$}}%      case 1 is displaystyle
{\hbox{\boldmath$\textstyle{#1}$}}%         case 2 is textstyle
{\hbox{\boldmath$\scriptstyle{#1}$}}%       case 3 is scriptstyle
{\hbox{\boldmath$\scriptscriptstyle{#1}$}}% case 4 is scriptscriptstyle
}}
\def\vec{\mbf}


%% General maths commands
\newcommand{\lr}[1]{\left(#1\right)} 
\def\d{\textrm{d}} % Define the "d" for use in integrals.
\newcommand{\logit}[1]{\text{logit}\!\left(#1\right)} % logit function
\newcommand{\logistic}[1]{\text{logistic}\!\left(#1\right)} % logistic function
\DeclareMathOperator*{\argmax}{arg\,max} % argmax
\DeclareMathOperator*{\argmin}{arg\,min} % argmin
\DeclareMathOperator{\Lagr}{\mathcal{L}} % Lagrangian L
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} % number within align*
\newcommand{\explr}[1]{\exp\!\left(#1\right)} % exp function with brackets (makes converting between e^{#1} and exp(#1) extremely easy)
\newcommand{\lnlr}[1]{\ln\!\left(#1\right)} % ln function with brackets 
\newcommand{\loglr}[1]{\log\!\left(#1\right)} % ln function with brackets 

%% General stats commands 
\newcommand{\Gau}{{\text{Gau}}}
\def\inddist{\:\stackrel{\text{ind}}{\sim}\:}
\newcommand{\simiid}{\overset{\text{iid}}{\sim}}
\newcommand{\E}[1]{\mathbb{E}\left(#1\right)} % Expectation operator
\newcommand{\ENoLR}[1]{\mathbb{E}(#1)} % Expectation operator
\newcommand{\ECurly}[1]{\mathbb{E}\left\{#1\right\}} % Expec operator, curly brackets
\newcommand{\ESquare}[1]{\mathbb{E}\left[#1\right]} % Expec operator, square brackets
\newcommand{\var}[1]{{\rm var}\left(#1\right)} % variance operator
\newcommand{\precision}[1]{{\rm prec}\left(#1\right)} % precision operator
\newcommand{\precisionNoLR}[1]{{\rm prec}(#1)} % precision operator
\newcommand{\varCurly}[1]{{\rm var}\left\{#1\right\}} % variance operator, curly brackets
\newcommand{\varSquare}[1]{{\rm var}\left[#1\right]} % variance operator, square brackets 
\newcommand{\cov}[2]{{\rm cov}\left(#1,\;\; #2\right)} % covariance operator
\newcommand{\covCurly}[2]{{\rm cov}\left\{#1,\;\; #2\right\}} % covariance operator, curly brackets
\newcommand{\covCurlyConditional}[3]{{\rm cov}\left\{#1,\; #2 \mid #3\right\}} % covariance operator, curly brackets
\newcommand{\covSquare}[2]{{\rm cov}\left[#1,\;\; #2\right]} % covariance operator, square brackets
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}} % Independent Symbol: \indep

%% Linear algebra commands
\newcommand{\rank}[1]{{\rm rank}\left(#1\right)}
\newcommand{\tr}[1]{{\rm tr}\left(#1\right)}
\newcommand{\tp}{{\!\scriptscriptstyle \top}}
\newcommand{\vecFN}[1]{{\rm vec \!}\left(#1\right)} % vec operator
\newcommand{\diag}[1]{\text{diag}\left(#1\right)} % diag function: \diag

%% Predictor and MSPE definitions 
\newcommand{\pYgivenZ}[1]{\hat{p}_{Y|\vec{Z}}\left(#1\right)} 
\newcommand{\pmugivenZ}[1]{\hat{p}_{\mu|\vec{Z}}\left(#1\right)} 
\newcommand{\pmugivenZApprox}[1]{\check{p}_{\mu|\vec{Z}}\left(#1\right)} 
\newcommand{\pZgivenZ}[1]{\hat{p}_{Z|\vec{Z}}\left(#1\right)} 
\newcommand{\MSPE}[1]{\text{MSPE}\left\{#1\right\}} 
\newcommand{\MSPEtwoarg}[2]{\text{MSPE}\left\{#1, #2\right\}} 


%% Define a \hat{} that will fit over any function input. 
\usepackage{scalerel,stackengine}
\stackMath
\newcommand\reallywidehat[1]{%
\savestack{\tmpbox}{\stretchto{%
  \scaleto{%
    \scalerel*[\widthof{\ensuremath{#1}}]{\kern-.6pt\bigwedge\kern-.6pt}%
    {\rule[-\textheight/2]{1ex}{\textheight}}%WIDTH-LIMITED BIG WEDGE
  }{\textheight}% 
}{0.5ex}}%
\stackon[1pt]{#1}{\tmpbox}%
}


%% New for this vignette
\renewcommand{\tt} {\texttt}
\let\code=\texttt
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\let\proglang=\textsf

\author{Matthew Sainsbury-Dale, Andrew Zammit-Mangion, and Noel Cressie}

\title{Modelling, Fitting, and Prediction with Non-Gaussian Spatial and Spatio-Temporal Data using \pkg{FRK}}

\usepackage[authoryear]{natbib}

\bibliographystyle{plainnat}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\maketitle

\begin{abstract}
 Non-Gaussian spatial and spatial-temporal data are becoming increasingly prevalent, arising from studies as far apart as small area demographics (counts) and global remote sensing (radiant energies). 
  \pkg{FRK} is an \proglang{R} package for spatial/spatio-temporal modelling and prediction with large data sets. 
In this vignette, we demonstrate the modelling of non-Gaussian data  using \pkg{FRK}. 
The existing functionality of \pkg{FRK} is retained with this advance; in particular, it makes use of automatic basis-function construction, it can handle both point-referenced and areal data simultaneously, and it predicts process values at any spatial support from these data. See the vignette ``FRK\_intro'' for general usage of the package. 
\end{abstract}



\tableofcontents 

\section{Methodology}\label{SEC:Methodology}

The statistical model used by \pkg{FRK} in a non-Gaussian setting is a spatial generalised linear mixed (GLMM) model \citep{Diggle_1998_spatial_GLMM}, a hierarchical model consisting of two layers.
 In the \textit{process} layer, we model the conditional mean of the data as a transformation of a latent spatial process, where the spatial process is modelled as a low-rank spatial random effects model; see Section  \ref{subsection:04-01:ProcessLayer}. 
 The process layer, which governs the conditional mean of the data, retains many similarities to that in previous versions of the package, as described by \cite{FRK_paper} and in the vignette ``FRK\_intro''. 
 In the \textit{data} layer, we use a conditionally independent exponential-family model for the data; see Section \ref{subsection:04-02:DataLayer}. 
In Sections \ref{subsection:02-03:Estimation} and \ref{subsection:04-03:Prediction} we briefly discuss parameter estimation, and spatial prediction and uncertainty quantification.

\subsection{The process layer}\label{subsection:04-01:ProcessLayer}

 Denote the latent spatial process as $Y(\cdot) \equiv \{Y(\vec{s}) \colon \vec{s}\in D\}$, where $\vec{s}$ indexes space in the spatial domain of interest $D$. 
 The model for $Y(\cdot)$ is the so-called spatial random effects (SRE) model \citep{Cressie_Johannesson_2008_FRK}, 
\begin{equation}\label{eqn:04-01:Y(s)}
    Y(\vec{s}) = \vec{t}(\vec{s})^\tp \vec{\alpha} + \vec{\phi}(\vec{s})^\tp \vec{\eta} + \xi(\vec{s}); \quad \vec{s} \in D, 
\end{equation}
where $\vec{t}(\cdot)$ are spatially referenced covariates with associated regression parameters $\vec{\alpha}$, $\vec{\phi}(\cdot) \equiv \left(\phi_1(\cdot), \dots, \phi_r(\cdot) \right)^\tp$ is an $r$-dimensional vector of pre-specified spatial basis functions with associated random coefficients $\vec{\eta}$, and $\xi(\cdot)$ is a fine-scale random process that is `almost' uncorrelated.

\pkg{FRK} discretises the domain of interest $D$ into $N$ small, non-overlapping basic areal units (BAUs) $\{A_i:i = 1, \dots, N\}$ such that $D = \cup_{i = 1}^N A_i$. 
BAUs are a key element of \pkg{FRK}, as they provide a framework that allows one to use both point-referenced and areal data simultaneously, and one that facilitates the spatial change-of-support problem. 
After discretisation via the BAUs, we obtain the vectorised version of (\ref{eqn:04-01:Y(s)}), 
\begin{equation}\label{Ch4:eqn:vecY}
    \vec{Y} = \vec{T}\vec{\alpha} + \vec{S}\vec{\eta} + \vec{\xi},
\end{equation}
 where $\vec{Y}$ is an $N$-dimensional vector, $\vec{T}$ and $\vec{S}$ are known design matrices, and $\vec{\xi}$ is the vector associated with the fine-scale process. 

 We model the fine-scale random effects as being independent and identically distributed Gaussian random variables with variance $\sigma^2_\xi$; we model $\vec{\eta}$ as a mean-zero multivariate-Gaussian random variable, typically using a sparse precision matrix parametrisation formualtion in a non-Gaussian setting.
 
Following standard generalised linear model theory \citep{McCullagh_Nelder_1989_GLM}, \pkg{FRK} v.2 uses a link function, $g(\cdot)$, to model $Y(\cdot)$ as a transformation of the mean process, $\mu(\cdot)$:
\[
g\left(\mu(\vec{s})\right) = Y(\vec{s}); \quad \vec{s} \in D.
\]
The mean process evaluated over the BAUs is 
\[
\mu_i = g^{-1}(Y_i), \; i = 1, \dots, N,
\]
where $g^{-1}(\cdot)$ is the inverse link function. An identity link function and a Gaussian data model yields the standard Gaussian FRK model.


\subsection{The data layer}\label{subsection:04-02:DataLayer}

Given $m$ observations with footprints spanning one or more BAUs, we define the observation supports as $B_j \equiv \cup_{i\in c_j} A_i$ for $j = 1, \dots, m$, where $c_j$ is a non-empty set in the power set of $\{1, \dots, N\}$, and define $D^O \equiv \{B_j : j = 1, \dots, m\}$. 
Let $Z_j \equiv Z(B_j)$, $j = 1, \dots, m$. 
The vector of observations (the data vector) is then $\vec{Z} \equiv \left(Z_1, \dots, Z_m\right)^\tp$.

Since each $B_j \in D^O$ is either a BAU or a union of BAUs, one can construct an $m\times N$ matrix 
\[
\vec{C}_Z \equiv \Big(w_i\mathbb{I}(A_i \subset B_j) : i = 1, \dots, N; j = 1, \dots, m\Big),
\]
where $\mathbb{I}(\cdot)$ is the indicator function, which creates a linear mapping from $\vec{\mu} \equiv (\mu_i: i = 1, \dots, N)^\tp$ to evaluations of the mean process over the observation supports;
\begin{equation}\label{eqn:04-01:mu_Z}
\vec{\mu}_Z \equiv \vec{C}_Z\vec{\mu}.  
\end{equation}
% In \pkg{FRK} v.2, the weights $w_i$ may be controlled through the \code{wts} field of the BAU object. 
% If \code{wts} is \code{NULL}, each $w_i$ is set to one, so that all BAUs are equally weighted. 
The \mbox{\code{normalise\_wts}} argument in \fct{SRE} controls whether the linear mapping of $\vec{C}_Z$ corresponds to a weighted sum or a weighted average; if \mbox{\code{normalise\_wts = TRUE}}, then the weights $w_i$ are normalised so that the rows of $\vec{C}_Z$ sum to one, and the mapping represents a weighted average.


We assume that $[Z_j \mid \mu(\cdot), \psi] = [Z_j \mid \vec{\mu}_{Z, j}, \psi]$, where $\psi$ is a (nuisance) dispersion parameter and, for a generic random quantities $A$ and $B$, $[A \mid B]$ denotes the probability distribution of $A$ given $B$. 
That is, a given observation depends only on the value of the mean process at the corresponding observation support, rather than on the process over the whole domain. 
As a result, conditional on the latent spatial process, all observations are conditionally independent:
\[
[\vec{Z} \mid \mu(\cdot), \psi] = \prod_{j=1}^m[Z_j \mid \vec{\mu}_{Z, j}, \psi].
\]
We model the conditional distribution $[Z_j \mid \vec{\mu}_{Z, j}, \psi]$ as a member of the exponential family \citep[Sec.~2.2.2]{McCullagh_Nelder_1989_GLM}, with conditional expectation 
$\mu(B_j) \equiv \ECurly{Z_j \mid \vec{\mu}_{Z, j}, \psi}$.   

The model employed by \pkg{FRK} v.2 can be summarised as follows. 
\begin{gather}
    Z_j \mid \vec{\mu}_{Z,j}, \psi \inddist \text{EF}(\vec{\mu}_{Z,j}, \psi), \quad j = 1, \dots, m, \label{eqn:new_model_Z}\\
    \vec{\mu}_Z = \vec{C}_Z \vec{\mu}, \\
    g(\vec{\mu}) = \vec{Y}, \\
    \vec{Y} = \vec{T} \vec{\alpha} + \vec{S} \vec{\eta} + \vec{\xi}, \label{eqn:new_model_Y}\\
    \vec{\eta} \mid \vec{\vartheta} \sim \Gau(\vec{0}, \vec{Q}^{-1}), \\
    \vec{\xi} \mid \sigma^2_\xi \sim \Gau(\vec{0}, \sigma^2_\xi \vec{V}) \label{eqn:new_model_priors}.
\end{gather}
 where $\vec{V}$ is a known diagonal matrix with positive entries on the diagonal and $\sigma^2_\xi$ is either unknown and estimated, or provided by the user. 

\subsection{Estimation}\label{subsection:02-03:Estimation}

The complete-data likelihood function for our model is
\begin{equation}\label{eqn:04:Joint_Likelihood}
    L(\vec{\theta}; \vec{Z}, \vec{\eta}, \vec{\xi})
    \equiv 
    [\vec{Z}, \vec{\eta}, \vec{\xi}]
    =
    [\vec{Z} \mid \vec{\mu}_Z, \psi]
    [\vec{\eta} \mid \vec{\vartheta}]
    [\vec{\xi} \mid \sigma^2_\xi], 
\end{equation}
 where $
 \vec{\theta}
 \equiv
 (
 \vec{\alpha}^\tp,
 \vec{\vartheta}^\tp, 
 \sigma^2_\xi, 
 \psi
 )^\tp$ and $\vec{\vartheta}$ are variance components, and its logarithm is 
\begin{equation}\label{eqn:04:Joint_Log_Likelihood}
    l(\vec{\theta}; \vec{Z}, \vec{\eta}, \vec{\xi}) 
    \equiv 
    \ln{L(\vec{\theta}; \vec{Z}, \vec{\eta}, \vec{\xi})}
    =
    \ln{[\vec{Z} \mid \vec{\mu}_Z, \psi]}
    +
    \ln{[\vec{\eta} \mid \vec{\vartheta}]}
    +
    \ln{[\vec{\xi} \mid \sigma^2_\xi]}.
\end{equation}
Under our modelling assumptions, the conditional density functions  $[\vec{\eta}\mid\vec{\vartheta}]$ and $[\vec{\xi} \mid \sigma^2_\xi]$ are invariant to the specified link function and assumed distribution of the response variable. 
 Of course, this invariance does not hold for $[\vec{Z} \mid \vec{\mu}_Z, \psi]$. 
As we only consider data models in the exponential family, $\ln{[\vec{Z}  \mid  \vec{\mu}_Z, \psi]}$ may be expressed as  
\begin{equation}\label{eqn:ln[Z|Y],ExpFam}
\ln{[\vec{Z} \mid \vec{\mu}_Z, \psi]}
=
\sum_{j=1}^m\left\{
\frac{Z_j\lambda(\mu_{Z, j}) - b(\lambda(\mu_{Z, j}))}{a(\psi)} + c(Z_j, \psi)\right\},
\end{equation}
where $a(\cdot)$, $b(\cdot)$, and $c(\cdot, \cdot)$ are deterministic functions specific to the exponential family member, and $\lambda(\cdot)$ is the canonical parameter. 

The marginal likelihood, which does not depend on the random effects, is given by
\begin{equation}\label{eqn:02-04:LikelihoodTheta}
    L^*(\vec{\theta}; \vec{Z}) 
    \equiv
    \int_{\mathbb{R}^{{p}}}
    L(\vec{\theta} ; \vec{Z}, \vec{u}) \d \vec{u}, 
\end{equation}
where $\vec{u} \equiv (\vec{\eta}^\tp, \vec{\xi}^\tp)^\tp \in \mathbb{R}^{p}$, and ${p}$ is the total number of random effects in the model.
When the data are non-Gaussian, the integral in (\ref{eqn:02-04:LikelihoodTheta}) is typically intractable and must be approximated either numerically or analytically. 
In \pkg{FRK}, we use the Laplace approximation, implemented using the \proglang{R} package \pkg{TMB} \citep{Kristensen_2016_TMB}. 


Given as input a \proglang{C++} template function which defines the complete-data log-likelihood function (\ref{eqn:04:Joint_Log_Likelihood}), \pkg{TMB} \citep{Kristensen_2016_TMB} computes the Laplace approximation of the marginal log-likelihood, and automatically computes its derivatives, which are then called from within \pkg{FRK} by an optimising function specified by the user (\fct{nlminb} is used by default). 
 \pkg{TMB} uses \pkg{CppAD} \citep{CppAD_Package} for automatic differentiation, and the linear algebra libraries \pkg{Eigen} \citep{Eigen} and \pkg{Matrix} \citep{Matrix_Package} for vector and matrix operations in \proglang{C++} and \proglang{R}, respectively; use of these packages yields good computational efficiency. 
\pkg{TMB}'s implementation of automatic differentiation is a key reason why we can cater for a variety of response distributions and link functions, as we do not need to consider each combination on a case-by-case basis.


\subsection{Prediction and uncertainty quantification}\label{subsection:04-03:Prediction}

There are three primary quantities of interest in this framework: The latent process $Y(\cdot)$, the  mean process $\mu(\cdot)$, and the noisy data process. 
 To produce predictions and associated uncertainties, we need to determine the posterior distribution of these quantities.

It can be shown that the Laplace approximation implies that the posterior distribution of the random effects, $\vec{u} \mid \vec{Z}, \vec{\theta}$ is approximated to be Gaussian. 
 This, in turn, implies that the posterior distribution of $\vec{Y}$ is also approximated to be Gaussian, and hence inference on $Y(\cdot)$ can be done using closed form solutions. 
  However, the posterior distribution of non-linear functions of $Y(\cdot)$ (e.g., the mean process) are typically not available in closed form, and in this case some form of approximation is required.
   Hence, we choose to use a Monte Carlo (MC) framework.
   
For each quantity, we use the posterior expectation as our predictor. 
A commonly used metric for uncertainty quantification is the root-mean-squared prediction error (RMSPE). 
In a non-Gaussian setting, it can be difficult to interpret the RMSPE, and it is often more intuitive to quantify uncertainty through the width of the posterior predictive intervals. Hence, in \pkg{FRK}, we also provide the user with user-specified percentiles of the posterior predictive distribution. 
 These quantities can be computed straightforwardly using MC sampling. 



\subsubsection{Arbitrary prediction regions}


Often, one does not wish to predict over a single BAU, but over regions spanning multiple BAUs.
Define the set of prediction regions as 
$D^P \equiv \{\tilde{B}_k : k = 1, \dots, N_P\}$, where $\tilde{B}_k \equiv \cup_{i\in c_k} A_i$, and where $c_k$ is some non-empty set in the power set of $\{1, \dots, N\}$. 
Like the data, the prediction regions $\{\tilde{B}_k\}$ may overlap.  
In practice, $\tilde{B}_k$  may not include entire BAUs; in this case, we assume that a prediction region contains a BAU if and only if there is at least some overlap between the BAU and the prediction region.
Prediction over $D^P$ requires some form of aggregation across relevant BAUs.
Since in the non-Gaussian setting aggregation must be done on the original scale, we restrict prediction over arbitrary regions to the mean (or the noisy data process). 
Therefore, predictions of the latent process $Y(\cdot)$ are not allowed over arbitrary prediction regions. 

Consider the predictions $\{\mu_P(\tilde{B}_k) : k = 1, \dots, N_P\}$, where $\mu_P(\cdot) \equiv \mu(\cdot \mid \vec{Z}, \vec{\theta})$. 
These predictions are weighted sums of the predictions over the associated BAUs. 
Specifically,
\[
    \mu_{P, k} \equiv \mu_P(\tilde{B}_k) = 
   \sum_{i = 1}^N \tilde{w}_i \mathbb{I}(A_i \subset \tilde{B}_k)\mu_i; \quad i = 1, \dots, N;\;  k = 1, \dots, N_P;\; \tilde{B}_k \in D^P,
\]
where, in a similar fashion to the incidence matrix $\vec{C}_Z$, the weights $\{\tilde{w}_i\}$ are optionally provided by the user in the \code{wts} field of the BAU object, and may be normalised if \mbox{\code{normalise\_wts = TRUE}}. 
If \code{wts} is \code{NULL}, the BAUs are assumed to be equally weighted. 
Define $\vec{\mu}_P \equiv (\mu_{P, k} : k = 1, \dots, N_P)^\tp$. 
Since each element in $D^P$ is the union of subsets of $D^G$, one can construct a matrix, 
\[
\vec{C}_P \equiv \left(\tilde{w}_i : i = 1, \dots, N; k = 1, \dots, N_P\right),
\]
such that $\vec{\mu}_P = \vec{C}_P \vec{\mu}$. Again, we use MC sampling to predict $\vec{\mu}_P$. 

\section{Example: Non-Gaussian, point-referenced spatial data}

In this part of the vignette we apply \pkg{FRK} to the case when we have non-Gaussian, point-referenced spatial data. 
 For simplicity, in this vignette we only consider inference on the plane; for other manifolds, such as the sphere, see the vignette ``FRK\_intro''. 
 
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(}\hlstr{"FRK"}\hlstd{)}       \hlcom{# for carrying out FRK       }
\hlkwd{library}\hlstd{(}\hlstr{"sp"}\hlstd{)}        \hlcom{# for defining points/polygons}
\hlkwd{library}\hlstd{(}\hlstr{"dplyr"}\hlstd{)}     \hlcom{# for easy data manipulation}
\hlkwd{library}\hlstd{(}\hlstr{"ggplot2"}\hlstd{)}   \hlcom{# for plotting}
\hlkwd{library}\hlstd{(}\hlstr{"ggpubr"}\hlstd{)}    \hlcom{# for arranging plots}
\end{alltt}
\end{kframe}
\end{knitrout}

First, we simulate a Poisson data set. 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{m} \hlkwb{<-} \hlnum{1000}                                                  \hlcom{# Sample size}
\hlkwd{RNGversion}\hlstd{(}\hlstr{"3.6.0"}\hlstd{);} \hlkwd{set.seed}\hlstd{(}\hlnum{1}\hlstd{)}                           \hlcom{# Fix seed}
\hlstd{zdf} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{runif}\hlstd{(m),} \hlkwc{y}\hlstd{=} \hlkwd{runif}\hlstd{(m))}               \hlcom{# Generate random locs}
\hlstd{zdf}\hlopt{$}\hlstd{Y} \hlkwb{<-} \hlkwd{sin}\hlstd{(}\hlnum{8} \hlopt{*} \hlstd{zdf}\hlopt{$}\hlstd{x)} \hlopt{+} \hlkwd{cos}\hlstd{(}\hlnum{8} \hlopt{*} \hlstd{zdf}\hlopt{$}\hlstd{y)} \hlopt{+} \hlnum{0.5} \hlopt{*} \hlkwd{rnorm}\hlstd{(m)}  \hlcom{# Simulate latent process}
\hlstd{zdf}\hlopt{$}\hlstd{z} \hlkwb{<-} \hlkwd{rpois}\hlstd{(m,} \hlkwc{lambda} \hlstd{= zdf}\hlopt{$}\hlstd{Y}\hlopt{^}\hlnum{2}\hlstd{)}                        \hlcom{# Simulate data}
\hlkwd{coordinates}\hlstd{(zdf)} \hlkwb{=} \hlopt{~}\hlstd{x}\hlopt{+}\hlstd{y}                                    \hlcom{# Turn into sp object}
\end{alltt}
\end{kframe}
\end{knitrout}


Now, we run \pkg{FRK}. There is an `expert' way of using \pkg{FRK}, which involves using the functions \fct{auto\_BAUs} and \fct{auto\_basis} to automatically construct BAUs and basis functions from the data, \fct{SRE} to initialise the SRE model object and perform data preprocessing, and \fct{SRE.fit} to fit the model object. 
 This `expert' way is documented in the vignette ``FRK\_intro''. 
 Alternatively, there is a `simple' way of using \pkg{FRK} that uses the high-level wrapper function \fct{FRK} that calls these functions under-the-hood; in this vignette, we will use the `simple' way. 
 
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{S} \hlkwb{<-} \hlkwd{FRK}\hlstd{(}\hlkwc{f} \hlstd{= z} \hlopt{~} \hlnum{1}\hlstd{,}               \hlcom{# Formula to FRK}
         \hlkwd{list}\hlstd{(zdf),}               \hlcom{# All datasets are supplied in list}
         \hlkwc{nres} \hlstd{=} \hlnum{1}\hlstd{,}                \hlcom{# Reduce run-time using only 1 basis function resolution}
         \hlkwc{response} \hlstd{=} \hlstr{"poisson"}\hlstd{,}    \hlcom{# Poisson data model}
         \hlkwc{link} \hlstd{=} \hlstr{"square-root"}\hlstd{)}    \hlcom{# square-root link function}
\hlstd{pred} \hlkwb{<-} \hlkwd{predict}\hlstd{(S)}                \hlcom{# prediction stage}
\end{alltt}
\end{kframe}
\end{knitrout}

\pkg{FRK} includes two plotting methods, \fct{plot} and \fct{plot\_spatial\_or\_ST}; the former takes an SRE object and the result of a call to predict, and returns a list of \class{ggplot} objects containing the predictions and uncertainty quantification of those predictions, while the former is a general-purpose function for \class{Spatial*DataFrame} and \class{STFDF} objects. See Figure \ref{fig:example1}.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{plot_list} \hlkwb{<-} \hlkwd{plot}\hlstd{(S, pred, zdf)}
\hlkwd{ggarrange}\hlstd{(plot_list}\hlopt{$}\hlstd{z} \hlopt{+} \hlkwd{labs}\hlstd{(}\hlkwc{fill} \hlstd{=} \hlstr{"data"}\hlstd{),}
          \hlstd{plot_list}\hlopt{$}\hlstd{p_mu} \hlopt{+} \hlkwd{labs}\hlstd{(}\hlkwc{fill} \hlstd{=} \hlstr{"pred."}\hlstd{),}
          \hlstd{plot_list}\hlopt{$}\hlstd{interval90_mu} \hlopt{+} \hlkwd{labs}\hlstd{(}\hlkwc{fill} \hlstd{=} \hlstr{"pred.\textbackslash{}nuncertainty"}\hlstd{),}
          \hlkwc{nrow} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{legend} \hlstd{=} \hlstr{"top"}\hlstd{)}
\end{alltt}
\end{kframe}\begin{figure}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-4-1} 

}

\caption{(Left) Simulated poisson data. (Centre) Prediction of the mean process. (Right) Uncertainty quantification of predictions, specifically the width of the 90\% posterior predictive interval.\label{fig:example1}}\label{fig:unnamed-chunk-4}
\end{figure}


\end{knitrout}




\bibliography{FRKv2}

\end{document}
