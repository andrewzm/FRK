% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FRK_wrapper.R, R/SRE.R, R/SREfit.R,
%   R/SREpredict.R, R/SREutils.R, R/SREvalidation.R
\name{FRK}
\alias{FRK}
\alias{SRE}
\alias{SRE.fit}
\alias{predict,SRE-method}
\alias{logLik,SRE-method}
\alias{nobs,SRE-method}
\alias{coef,SRE-method}
\alias{coef_uncertainty,SRE-method}
\alias{simulate}
\alias{fitted,SRE-method}
\alias{residuals,SRE-method}
\alias{AIC,SRE-method}
\alias{BIC,SRE-method}
\title{Construct SRE object, fit and predict}
\usage{
FRK(
  f,
  data,
  basis = NULL,
  BAUs = NULL,
  est_error = TRUE,
  average_in_BAU = TRUE,
  sum_variables = NULL,
  normalise_wts = TRUE,
  fs_model = "ind",
  vgm_model = NULL,
  K_type = c("block-exponential", "precision", "unstructured"),
  n_EM = 100,
  tol = 0.01,
  method = c("EM", "TMB"),
  lambda = 0,
  print_lik = FALSE,
  response = c("gaussian", "poisson", "gamma", "inverse-gaussian", "negative-binomial",
    "binomial"),
  link = c("identity", "log", "sqrt", "logit", "probit", "cloglog", "inverse",
    "inverse-squared"),
  optimiser = nlminb,
  fs_by_spatial_BAU = FALSE,
  known_sigma2fs = NULL,
  taper = NULL,
  simple_kriging_fixed = FALSE,
  ...
)

SRE(
  f,
  data,
  basis,
  BAUs,
  est_error = TRUE,
  average_in_BAU = TRUE,
  sum_variables = NULL,
  normalise_wts = TRUE,
  fs_model = "ind",
  vgm_model = NULL,
  K_type = c("block-exponential", "precision", "unstructured"),
  normalise_basis = TRUE,
  response = c("gaussian", "poisson", "gamma", "inverse-gaussian", "negative-binomial",
    "binomial"),
  link = c("identity", "log", "sqrt", "logit", "probit", "cloglog", "inverse",
    "inverse-squared"),
  include_fs = TRUE,
  fs_by_spatial_BAU = FALSE,
  ...
)

SRE.fit(
  object,
  n_EM = 100L,
  tol = 0.01,
  method = c("EM", "TMB"),
  lambda = 0,
  print_lik = FALSE,
  optimiser = nlminb,
  known_sigma2fs = NULL,
  taper = NULL,
  simple_kriging_fixed = FALSE,
  ...
)

\S4method{predict}{SRE}(
  object,
  newdata = NULL,
  obs_fs = FALSE,
  pred_time = NULL,
  covariances = FALSE,
  nsim = 400,
  type = "mean",
  k = NULL,
  percentiles = c(5, 95),
  kriging = "simple"
)

\S4method{logLik}{SRE}(object)

\S4method{nobs}{SRE}(object, ...)

\S4method{coef}{SRE}(object, ...)

\S4method{coef_uncertainty}{SRE}(
  object,
  percentiles = c(5, 95),
  nsim = 400,
  random_effects = FALSE
)

simulate(object, newdata = NULL, nsim = 400, conditional_fs = FALSE, ...)

\S4method{fitted}{SRE}(object, ...)

\S4method{residuals}{SRE}(object, type = "pearson")

\S4method{AIC}{SRE}(object, k = 2)

\S4method{BIC}{SRE}(object)
}
\arguments{
\item{f}{\code{R} formula relating the dependent variable (or transformations thereof) to covariates}

\item{data}{list of objects of class \code{SpatialPointsDataFrame}, \code{SpatialPolygonsDataFrame}, \code{STIDF}, or  \code{STFDF}. If using space-time objects, the data frame must have another field, \code{t}, containing the time index of the data point}

\item{basis}{object of class \code{Basis} (or \code{TensorP_Basis})}

\item{BAUs}{object of class \code{SpatialPolygonsDataFrame}, \code{SpatialPixelsDataFrame}, \code{STIDF}, or \code{STFDF}. The object's data frame must contain covariate information as well as a field \code{fs} describing the fine-scale variation up to a constant of proportionality. If the function \code{FRK()} is used directly, then BAUs are created automatically, but only coordinates can then be used as covariates}

\item{est_error}{(applicable only if \code{response} = "gaussian") flag indicating whether the measurement-error variance should be estimated from variogram techniques. If this is set to 0, then \code{data} must contain a field \code{std}. Measurement-error estimation is currently not implemented for spatio-temporal datasets}

\item{average_in_BAU}{if \code{TRUE}, then multiple data points falling in the same BAU are averaged; the measurement error of the averaged data point is taken as the average of the individual measurement errors}

\item{sum_variables}{if \code{average_in_BAU == TRUE}, the string \code{sum_variables} indicates which data variables (can be observations or covariates) are to be summed rather than averaged}

\item{normalise_wts}{if \code{TRUE}, the rows of the incidence matrices \ifelse{html}{\out{<i><b>C</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{C}_Z}{C_Z}} and \ifelse{html}{\out{<i><b>C</b><sub>P</sub></i>}}{\eqn{\boldsymbol{C}_P}{C_P}} are normalised to sum to 1, so that the mapping represents a weighted average; if false, no normalisation of the weights occurs (i.e., the mapping corresponds to a weighted sum)}

\item{fs_model}{if "ind" then the fine-scale variation is independent at the BAU level. Only the independent model is allowed for now, future implementation will include CAR/ICAR (in development)}

\item{vgm_model}{(applicable only if \code{response} = "gaussian") an object of class \code{variogramModel} from the package \code{gstat} constructed using the function \code{vgm}. This object contains the variogram model that will be fit to the data. The nugget is taken as the measurement error when \code{est_error = TRUE}. If unspecified, the variogram used is \code{gstat::vgm(1, "Lin", d, 1)}, where \code{d} is approximately one third of the maximum distance between any two data points}

\item{K_type}{the parameterisation used for the basis-function covariance matrix, \code{K}. If \code{method} = "EM", \code{K_type} can be "unstructured" or "block-exponential". If \code{method} = "TMB", \code{K_type} can be "precision" or "block-exponential". The default is "block-exponential", however if \code{FRK()} is used and \code{method} = "TMB", for computational reasons \code{K_type} is set to "precision"}

\item{n_EM}{(applicable only if \code{method} = "EM") maximum number of iterations for the EM algorithm}

\item{tol}{(applicable only if \code{method} = "EM") convergence tolerance for the EM algorithm}

\item{method}{parameter estimation method to employ. Currently "EM" and "TMB" are supported}

\item{lambda}{(applicable only if \code{K_type} = "unstructured") ridge-regression regularisation parameter (0 by default). Can be a single number, or a vector (one parameter for each resolution)}

\item{print_lik}{(applicable only if \code{method} = "EM") flag indicating whether to plot log-likelihood vs. iteration after convergence of the EM estimation algorithm}

\item{response}{string indicating the assumed distribution of the response variable. It can be "gaussian", "poisson", "negative-binomial", "binomial", "gamma", or "inverse-gaussian". If \code{method} = "EM", only "gaussian" can be used. Two distributions considered in this framework, namely the binomial distribution and the negative-binomial distribution, have an assumed-known ‘size’ parameter and a ‘probability of success’ parameter; see the details below for the exact parameterisations used, and how to provide these ‘size’ parameters}

\item{link}{string indicating the desired link function. Can be "log", "identity", "logit", "probit", "cloglog", "reciprocal", or "reciprocal-squared". Note that only sensible link-function and response-distribution combinations are permitted. If \code{method} = "EM", only "identity" can be used}

\item{optimiser}{(applicable only if \code{method} = "TMB") the optimising function used for model fitting when \code{method} = "TMB" (default is \code{nlminb}). Users may pass in a function object or a string corresponding to a named function. Optional parameters may be passed to \code{optimiser} via \code{...}. The only requirement of \code{optimiser} is that the first three arguments correspond to the initial parameters, the objective function, and the gradient, respectively (this may be achieved by simply constructing a wrapper function)}

\item{fs_by_spatial_BAU}{(applicable only in a spatio-temporal setting and if \code{method} = "TMB") if \code{TRUE}, then each spatial BAU is associated with its own fine-scale variance parameter; otherwise, a single fine-scale variance parameter is used}

\item{known_sigma2fs}{known value of the fine-scale variance parameter. If \code{NULL} (the default), the fine-scale variance parameter is estimated as usual. If \code{known_sigma2fs} is not \code{NULL}, the fine-scale variance is fixed to the supplied value; this may be a scalar, or vector of length equal to the number of spatial BAUs (if \code{fs_by_spatial_BAU = TRUE})}

\item{taper}{positive numeric indicating the strength of the covariance/partial-correlation tapering. Only applicable if \code{K_type} = "block-exponential", or if \code{K_type} = "precision" and the the basis-functions are irregular or the manifold is not the plane. If \code{taper} is \code{NULL} (default) and \code{method} = "EM", no tapering is applied; if \code{method} = "TMB", tapering must be applied (for computational reasons), and we set it to 3 if it is unspecified}

\item{simple_kriging_fixed}{commit to simple kriging at the fitting stage? If \code{TRUE}, model fitting is faster, but the option to conduct universal kriging at the prediction stage is removed}

\item{...}{other parameters passed on to \code{auto_basis()} and \code{auto_BAUs()} when calling \code{FRK()}, or the user specified function \code{optimiser()} when calling \code{FRK()} or \code{SRE.fit()}}

\item{normalise_basis}{flag indicating whether to normalise the basis functions so that they reproduce a stochastic process with approximately constant variance spatially}

\item{include_fs}{(applicable only if \code{method} = "TMB") flag indicating whether the fine-scale variation should be included in the model}

\item{object}{object of class \code{SRE} returned from the constructor \code{SRE()} containing all the parameters and information on the SRE model}

\item{newdata}{object of class \code{SpatialPoylgons}, \code{SpatialPoints}, or \code{STI}, indicating the regions or points over which prediction will be carried out. The BAUs are used if this option is not specified.}

\item{obs_fs}{flag indicating whether the fine-scale variation sits in the observation model (systematic error; indicated by \code{obs_fs = TRUE}) or in the process model (process fine-scale variation; indicated by \code{obs_fs = FALSE}, default). For non-Gaussian data models, and/or non-identity link functions, if \code{obs_fs = TRUE}, then the fine-scale variation is removed from the latent process \eqn{Y}; however, they are re-introduced for prediction of the conditonal mean \ifelse{html}{\out{<i> <b> &mu; </b></i>}}{\eqn{\boldsymbol{\mu}}{mu}} and simulated data \ifelse{html}{\out{<i> <b>Z</b><sup>*</sup> </i>}}{\eqn{\boldsymbol{Z}^*}{Z*}}}

\item{pred_time}{vector of time indices at which prediction will be carried out. All time points are used if this option is not specified}

\item{covariances}{(applicable only for \code{method} = "EM") logical variable indicating whether prediction covariances should be returned or not. If set to \code{TRUE}, a maximum of 4000 prediction locations or polygons are allowed}

\item{nsim}{number of i) MC samples at each location when using \code{predict} or ii) response vectors when using \code{simulate}}

\item{type}{(applicable only if \code{method} = "TMB") vector of strings indicating the quantities for which inference is desired. If "link" is in \code{type}, inference on the latent Gaussian process \eqn{Y(\cdot)}{Y(.)} is included; if "mean" is in \code{type}, inference on the mean process \eqn{\mu(\cdot)}{\mu(.)} is included (and the probability process, \eqn{\pi(\cdot)}{\pi(.)},  if applicable); if "response" is in \code{type}, inference on the noisy data \ifelse{html}{\out{<i> <b>Z</b><sup>*</sup> </i>}}{\eqn{\boldsymbol{Z}^*}{Z*}} is included}

\item{k}{(applicable only if \code{response} is "binomial" or "negative-binomial") vector of size parameters at each BAU}

\item{percentiles}{(applicable only if \code{method} = "TMB") a vector of scalars in (0, 100) specifying the desired percentiles of the posterior predictive distribution; if \code{NULL}, no percentiles are computed}

\item{kriging}{(applicable only if \code{method} = "TMB") string indicating the kind of kriging: "simple" ignores uncertainty due to estimation of the fixed effects, while "universal" accounts for this source of uncertainty}

\item{random_effects}{logical; if set to true, confidence intervals will also be provided for the random effects random effects \ifelse{html}{\out{<i> <b>&gamma;</b></i>}}{\eqn{\boldsymbol{\gamma}}{\gamma}} (see `?SRE` for details on these random effects)}

\item{conditional_fs}{condition on the fitted fine-scale random effects?}
}
\description{
The Spatial Random Effects (SRE) model is the central object in \pkg{FRK}. The function \code{FRK()} provides a wrapper for the construction and estimation of the SRE object from data, using the functions \code{SRE()} (the object constructor) and \code{SRE.fit()} (for fitting it to the data). Please see \code{\link{SRE-class}} for more details on the SRE object's properties and methods.
}
\details{
The following details provide a summary of the model and basic workflow
used in \pkg{FRK}. See Zammit-Mangion and Cressie
(2021) and Sainsbury-Dale, Zammit-Mangion and Cressie (2023) for further details.

\strong{Model description}

The hierarchical model implemented in \pkg{FRK} is a spatial generalised
linear mixed model (GLMM), which may be summarised as

\ifelse{html}{\out{<div style="text-align:center"> <i> Z<sub>j</sub> | <b>&mu;</b><sub>Z</sub>, &psi; ~ EF(&mu;<sub>Z<sub>j</sub></sub> , &psi;); &nbsp; &nbsp; &nbsp; j = 1, ..., m, </i></div>}}{\deqn{Z_j \mid \boldsymbol{\mu}_{Z}, \psi \sim EF(\mu_{Z_j}, \psi); \quad j = 1, \dots, m,}{Z_j | \mu_{Z}, \psi ~ EF(\mu_{Z_j}, \psi);  j = 1, \dots, m,}}
\ifelse{html}{\out{<div style="text-align:center"> <i> <b>&mu;</b><sub>Z</sub> = <b>C</b><sub>Z</sub> <b>&mu;</b>, </i></div>}}{\deqn{\boldsymbol{\mu}_Z = \boldsymbol{C}_Z\boldsymbol{\mu}}{\mu_Z = C_Z \mu}}
\ifelse{html}{\out{<div style="text-align:center"> <i> g(<b>&mu;</b>) = <b>Y</b>, </i></div>}}{\deqn{g(\boldsymbol{\mu}) = \boldsymbol{Y}}{g(\mu) = Y}}
\ifelse{html}{\out{<div style="text-align:center"> <i> <b>Y</b> = <b>T&alpha;</b> + <b>G&gamma;</b>  + <b>S&eta;</b> + <b>&xi;</b>, </i></div>}}{\deqn{\boldsymbol{Y} = \boldsymbol{T}\boldsymbol{\alpha} + \boldsymbol{\gamma}\boldsymbol{G} + \boldsymbol{S}\boldsymbol{\eta} + \boldsymbol{\xi}}{Y = T\alpha + G\gamma + S\eta + \xi}}
\ifelse{html}{\out{<div style="text-align:center"> <i> <b>&eta;</b> ~ N(<b>0</b>, <b>K</b>),</i></div>}}{\deqn{\boldsymbol{\eta} \sim N(\boldsymbol{0}, \boldsymbol{K})}{\eta ~ N(0, K)}}
\ifelse{html}{\out{<div style="text-align:center"> <i> <b>&xi;</b> ~ N(<b>0</b>, <b>&Sigma;</b><sub>&xi;</sub> ),</i></div>}}{\deqn{\boldsymbol{\xi} \sim N(\boldsymbol{0}, \boldsymbol{\Sigma}_\xi),}{\xi ~ N(0, \Sigma_\xi),}}
\ifelse{html}{\out{<div style="text-align:center"> <i> <b>&gamma;</b> ~ N(<b>0</b>, <b>&Sigma;</b><sub>&gamma;</sub> ),</i></div><br>}}{\deqn{\boldsymbol{\gamma} \sim N(\boldsymbol{0}, \boldsymbol{\Sigma}_\gamma),}{\gamma ~ N(0, \Sigma_\gamma),}}

where \ifelse{html}{\out{<i>Z<sub>j</sub></i>}}{\eqn{Z_j}} denotes a datum, \eqn{EF}  corresponds to a probability
distribution in the exponential family with dispersion parameter \eqn{\psi},
\ifelse{html}{\out{<i> <b>&mu;</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{\mu}_Z}{\mu_Z}} is the vector containing the conditional expectations of each datum,
\ifelse{html}{\out{<i> <b>C</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{C}_Z}{C_Z}} is a matrix which aggregates the BAU-level mean process over the observation supports,
\ifelse{html}{\out{<i> <b>&mu;</b></i>}}{\eqn{\boldsymbol{\mu}}{\mu}} is the mean process evaluated over the BAUs, \eqn{g} is a link function,
\ifelse{html}{\out{<i> <b>Y</b></i>}}{\eqn{\boldsymbol{Y}}{Y}} is a latent Gaussian process evaluated over the BAUs,
the matrix \ifelse{html}{\out{<i> <b>T</b></i>}}{\eqn{\boldsymbol{T}}{T}} contains regression covariates at the BAU level associated with the fixed effects \ifelse{html}{\out{<i> <b>&alpha;</b></i>}}{\eqn{\boldsymbol{\alpha}}{\alpha}},
the matrix \ifelse{html}{\out{<i> <b>G</b></i>}}{\eqn{\boldsymbol{G}}{G}} is a design matrix at the BAU level associated with random effects \ifelse{html}{\out{<i> <b>&gamma;</b></i>}}{\eqn{\boldsymbol{\gamma}}{\gamma}},
the matrix \ifelse{html}{\out{<i> <b>S</b></i>}}{\eqn{\boldsymbol{S}}{S}} contains basis-function evaluations over the BAUs associated with basis-function random effects \ifelse{html}{\out{<i> <b>&eta;</b></i>}}{\eqn{\boldsymbol{\eta}}{\eta}}, and \ifelse{html}{\out{<i> <b>&xi;</b></i>}}{\eqn{\boldsymbol{\xi}}{\xi}} is a vector containing fine-scale variation at the BAU level.

The prior distribution of the random effects, \ifelse{html}{\out{<i> <b>&gamma;</b></i>}}{\eqn{\boldsymbol{\gamma}}{\gamma}}, is a mean-zero multivariate Gaussian with diagonal covariance matrix, with each group of random effects associated with its own variance parameter. These variance parameters are estimated during model fitting. 

The prior distribution of the basis-function coefficients, \ifelse{html}{\out{<i><b>&eta;</b></i>}}{\eqn{\boldsymbol{\eta}}{\eta}}, is formulated
using either a covariance matrix \ifelse{html}{\out{<i> <b>K</b></i>}}{\eqn{\boldsymbol{K}}{K}} or precision matrix \ifelse{html}{\out{<i> <b>Q</b></i>}}{\eqn{\boldsymbol{Q}}{Q}}, depending on the argument
\code{K_type}. The parameters of these matrices are estimated during model fitting.

The prior distribution of the fine-scale random effects, \ifelse{html}{\out{<i> <b>&xi;</b></i>}}{\eqn{\boldsymbol{\xi}}{\xi}}, is a mean-zero multivariate Gaussian with diagonal covariance matrix,
\ifelse{html}{\out{<i> <b>&Sigma;</b><sub>&xi;</sub></i>}}{\eqn{\boldsymbol{\Sigma}_\xi}{\Sigma_\xi}}.
By default, \ifelse{html}{\out{<i> <b>&Sigma;</b><sub>&xi;</sub> = &sigma;<sup>2</sup><sub>&xi;</sub><b>V</b></i>}}{\eqn{\boldsymbol{\Sigma}_\xi = \sigma^2_\xi \boldsymbol{V}}{\Sigma_\xi = \sigma^2_\xi V}}, where \ifelse{html}{\out{<i> <b>V</b></i>}}{\eqn{\boldsymbol{V}}{V}} is a
known, positive-definite diagonal matrix whose elements are provided in the
field \code{fs} in the BAUs. In the absence of problem
specific fine-scale information, \code{fs} can simply be set to 1, so that
\ifelse{html}{\out{<i> <b>V</b> = <b>I</b></i>}}{\eqn{\boldsymbol{V} = \boldsymbol{I}}{V = I}}.
In a spatio-temporal setting, another model for \ifelse{html}{\out{<i> <b>&Sigma;</b><sub>&xi;</sub></i>}}{\eqn{\boldsymbol{\Sigma}_\xi}{\Sigma_\xi}}
can be used by setting \code{fs_by_spatial_BAU = TRUE}, in which case each
spatial BAU is associated with its own fine-scale variance parameter 
(see Sainsbury-Dale et al., 2023, Sec. 2.6).
In either case, the fine-scale variance parameter(s) are either estimated during model fitting, or provided by
the user via the argument \code{known_sigma2fs}.

\emph{Gaussian data model with an identity link function}


When the data is Gaussian, and an identity link function is used, the preceding
model simplifies considerably: Specifically,

\ifelse{html}{\out{
<div style="text-align:center"><i> <b>Z</b> = <b>C</b><sub>Z</sub><b>Y</b> + <b>C</b><sub>Z</sub><b>&delta;</b> + <b>e</b>,<br> </i></div>
}}{
\deqn{\boldsymbol{Z} = \boldsymbol{C}_Z\boldsymbol{Y} + \boldsymbol{C}_Z\boldsymbol{\delta} + \boldsymbol{e},}{Z = C_ZY + C_Z \delta + e,}
}

where
\ifelse{html}{\out{<i><b>Z</b></i>}}{\eqn{\boldsymbol{Z}}{Z}} is the data vector,
\ifelse{html}{\out{<i><b>&delta;</b></i>}}{\eqn{\boldsymbol{\delta}}{\delta}} is systematic error at the BAU level, and
\ifelse{html}{\out{<i><b>e</b></i>}}{\eqn{\boldsymbol{e}}{e}} represents independent measurement error.

\emph{Distributions with size parameters}

Two distributions considered in this framework, namely the binomial
distribution and the negative-binomial distribution, have an assumed-known
‘size’ parameter and a ‘probability of success’ parameter.
Given the vector of size parameters associated with the data,
\ifelse{html}{\out{<i> <b>k</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{k}_Z}{k_Z}}, the parameterisation used in \pkg{FRK} assumes that
\ifelse{html}{\out{<i>Z<sub>j</sub></i>}}{\eqn{Z_j}} represents either the number of `successes' from
\ifelse{html}{\out{<i>k<sub>Z<sub>j</sub></sub></i>}}{\eqn{k_{Z_j}}} trials (binomial data model) or that it represents the number of failures before
\ifelse{html}{\out{<i>k<sub>Z<sub>j</sub></sub></i>}}{\eqn{k_{Z_j}}} successes (negative-binomial data model).

When model fitting, the BAU-level size parameters
\ifelse{html}{\out{<i> <b> k </b></i>}}{\eqn{\boldsymbol{k}}{k}} are needed.
The user must supply these size parameters either through the data or though
the BAUs. How this is done depends on whether the data are areal or
point-referenced, and whether they overlap common BAUs or not.
The simplest case is when each observation is associated with a single BAU
only and each BAU is associated with at most one observation support; then,
it is straightforward to assign elements from
\ifelse{html}{\out{<i> <b>k</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{k}_Z}{k_Z}} to elements of
\ifelse{html}{\out{<i> <b> k </b></i>}}{\eqn{\boldsymbol{k}}{k}} and vice-versa, and so the user may provide either
\ifelse{html}{\out{<i> <b> k </b></i>}}{\eqn{\boldsymbol{k}}{k}} or
\ifelse{html}{\out{<i> <b>k</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{k}_Z}{k_Z}}.
If each observation is associated with
exactly one BAU, but some BAUs are associated with multiple observations,
the user must provide \ifelse{html}{\out{<i> <b>k</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{k}_Z}{k_Z}}, which is used to infer
\ifelse{html}{\out{<i> <b> k </b></i>}}{\eqn{\boldsymbol{k}}{k}}; in
particular,
\ifelse{html}{\out{<i>k<sub>i</sub> = &Sigma;<sub>j&isin;a<sub>i</sub></sub> k<sub>Z<sub>j</sub></sub></i> }}{\eqn{k_i = \sum_{j \in a_i} k_{Z_j}}},
\eqn{i = 1, \dots, N}, where
\ifelse{html}{\out{<i>a<sub>i</sub></i>}}{\eqn{a_i}}
denotes the indices of the observations associated with BAU
\ifelse{html}{\out{<i>A<sub>i</sub></i>}}{\eqn{A_i}}.
If one or more observations encompass multiple BAUs,
\ifelse{html}{\out{<i> <b> k </b></i>}}{\eqn{\boldsymbol{k}}{k}}
must be provided with the BAUs, as we cannot meaningfully
distribute
\ifelse{html}{\out{<i>k<sub>Z<sub>j</sub></sub></i>}}{\eqn{k_{Z_j}}}
over multiple BAUs associated with datum
\ifelse{html}{\out{<i>Z<sub>j</sub></i>}}{\eqn{Z_j}}.
In this case, we infer
\ifelse{html}{\out{<i> <b>k</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{k}_Z}{k_Z}} using
\ifelse{html}{\out{<i>k<sub>Z<sub>j</sub></sub> = &Sigma;<sub>i&isin;c<sub>j</sub></sub> k<sub>i</sub></i> }}{\eqn{k_{Z_j} = \sum_{i \in c_j} k_i}},
\eqn{j = 1, \dots, m}, where
\ifelse{html}{\out{<i>c<sub>j</sub></i>}}{\eqn{c_j}}
denotes the indices of the BAUs associated with observation
\ifelse{html}{\out{<i>Z<sub>j</sub></i>}}{\eqn{Z_j}}.


\strong{Set-up}

\code{SRE()} constructs a spatial random effects model from the user-defined formula, data object (a list
of spatially-referenced data), basis functions and a set of Basic Areal Units (BAUs).
It first takes each object in the list \code{data} and maps it to the BAUs -- this
entails binning point-referenced data into the BAUs (and averaging within the
BAU if \code{average_in_BAU = TRUE}), and finding which BAUs are associated
with observations. Following this, the incidence matrix, \ifelse{html}{\out{<i> <b>C</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{C}_Z}{C_Z}}, is
constructed.
All required matrices (\ifelse{html}{\out{<i><b>S</b></i>}}{\eqn{\boldsymbol{S}}{S}}, \ifelse{html}{\out{<i> <b>T</b></i>}}{\eqn{\boldsymbol{T}}{T}}, \ifelse{html}{\out{<i> <b>C</b><sub>Z</sub></i>}}{\eqn{\boldsymbol{C}_Z}{C_Z}}, etc.)
are constructed within \code{SRE()} and returned as part of the \code{SRE} object.
\code{SRE()} also intitialises the parameters and random effects using
sensible defaults. Please see
\code{\link{SRE-class}} for more details.
The functions \code{observed_BAUs()} and \code{unobserved_BAUs()} return the
indices of the observed and unobserved BAUs, respectively.

To include random effects in \pkg{FRK} please follow the notation as used in \pkg{lme4}. 
For example, to add a random effect according to a variable \code{fct}, simply add 
`\code{(1 | fct)}' to the formula used when calling \code{FRK()} or \code{SRE()}. 
Note that \pkg{FRK} only supports simple, uncorrelated random effects and 
that a formula term such as '\code{(1 + x | fct)}' will throw an error 
(since in \pkg{lme4} parlance this implies that the random effect corresponding to 
the intercept and the slope are correlated). If one wishes to model a an intercept and linear trend 
for each level in \code{fct}, 
then one can force the intercept and slope terms to be uncorrelated  by using 
the notation "\code{(x || fct)}", which is shorthand for 
"\code{(1 | fct) + (x - 1 | x2)}".

\strong{Model fitting}

\code{SRE.fit()} takes an object of class \code{SRE} and estimates all unknown
parameters, namely the covariance matrix \ifelse{html}{\out{<i><b>K</b></i>}}{\eqn{\boldsymbol{K}}{K}}, the fine scale variance
(\ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&xi;</sub></i>}}{\eqn{\sigma^2_{\xi}}} or \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&delta;</sub></i>}}{\eqn{\sigma^2_{\delta}}}, depending on whether Case 1
or Case 2 is chosen; see the vignette "FRK_intro") and the regression parameters \ifelse{html}{\out{<i> <b>&alpha;</b></i>}}{\eqn{\boldsymbol{\alpha}}{\alpha}}.
There are two methods of model fitting currently implemented, both of which
implement maximum likelihood estimation (MLE).
\describe{
 \item{MLE via the expectation maximisation
 (EM) algorithm. }{This method is implemented only
 for Gaussian data and an identity link function.
 The log-likelihood (given in Section 2.2 of the vignette) is evaluated at each
iteration at the current parameter estimate. Optimation continues until
convergence is reached (when the log-likelihood stops changing by more than
\code{tol}), or when the number of EM iterations reaches \code{n_EM}.
The actual computations for the E-step and M-step are relatively straightforward.
The E-step contains an inverse of an \eqn{r \times r}{r x r} matrix, where \eqn{r}
is the number of basis functions which should not exceed 2000. The M-step
first updates the matrix \ifelse{html}{\out{<i><b>K</b></i>}}{\eqn{\boldsymbol{K}}{K}}, which only depends on the sufficient
statistics of the basis-function coefficients \ifelse{html}{\out{<i> <b>&eta;</b></i>}}{\eqn{\boldsymbol{\eta}}{\eta}}. Then, the regression
parameters \ifelse{html}{\out{<i> <b>&alpha;</b></i>}}{\eqn{\boldsymbol{\alpha}}{\alpha}} are updated and a simple optimisation routine
(a line search) is used to update the fine-scale variance
\ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&delta;</sub></i>}}{\eqn{\sigma^2_{\delta}}} or \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&xi;</sub></i>}}{\eqn{\sigma^2_{\xi}}}. If the fine-scale errors and
measurement random errors are homoscedastic, then a closed-form solution is
available for the update of \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&xi;</sub></i>}}{\eqn{\sigma^2_{\xi}}} or \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&delta;</sub></i>}}{\eqn{\sigma^2_{\delta}}}.
Irrespectively, since the updates of \ifelse{html}{\out{<i> <b>&alpha;</b></i>}}{\eqn{\boldsymbol{\alpha}}{\alpha}}, and \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&delta;</sub></i>}}{\eqn{\sigma^2_{\delta}}}
or \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>&xi;</sub></i>}}{\eqn{\sigma^2_{\xi}}}, are dependent, these two updates are iterated until
the change in \ifelse{html}{\out{<i>&sigma;<sup>2</sup><sub>.</sub></i>}}{\eqn{\sigma^2_{\cdot}}} is no more than 0.1\%.}
 \item{MLE via \code{TMB}. }{This method is implemented for
 all available data models and link functions offered by \pkg{FRK}. Furthermore,
 this method facilitates the inclusion of many more basis function than possible
 with the EM algorithm (in excess of 10,000). \code{TMB} applies
 the Laplace approximation to integrate out the latent random effects from the
 complete-data likelihood. The resulting approximation of the marginal
 log-likelihood, and its derivatives with respect to the parameters, are then
 called from within \code{R} using the optimising function \code{optimiser}
 (default \code{nlminb()}).}
}


\emph{Wrapper for set-up and model fitting}

The function \code{FRK()} acts as a wrapper for the functions \code{SRE()} and
\code{SRE.fit()}. An added advantage of using \code{FRK()} directly is that it
automatically generates BAUs and basis functions based on the data. Hence
\code{FRK()} can be called using only a list of data objects and an \code{R}
formula, although the \code{R} formula can only contain space or time as
covariates when BAUs are not explicitly supplied with the covariate data.


\strong{Prediction}

Once the parameters are estimated, the \code{SRE} object is passed onto the
function \code{predict()} in order to carry out optimal predictions over the
same BAUs used to construct the SRE model with \code{SRE()}. The first part
of the prediction process is to construct the matrix \ifelse{html}{\out{<i> <b>S</b></i>}}{\eqn{\boldsymbol{S}}{S}} over the
prediction polygons. This is made computationally efficient by treating the
prediction over polygons as that of the prediction over a combination of BAUs.
This will yield valid results only if the BAUs are relatively small. Once the
matrix \ifelse{html}{\out{<i> <b>S</b></i>}}{\eqn{\boldsymbol{S}}{S}} is found, a standard Gaussian inversion (through conditioning)
using the estimated parameters is used for prediction.

\code{predict()} returns the BAUs (or an object specified in \code{newdata}),
which are of class \code{SpatialPixelsDataFrame}, \code{SpatialPolygonsDataFrame},
or \code{STFDF}, with predictions and
uncertainty quantification added.
If \code{method} = "TMB", the returned object is a list, containing the
previously described predictions, and a list of Monte Carlo samples.
The predictions and uncertainties can be easily plotted using \code{\link{plot}}
or \code{spplot} from the package \code{sp}.
}
\examples{
library("FRK")
library("sp")
## Generate process and data
m <- 250                                                   # Sample size
zdf <- data.frame(x = runif(m), y= runif(m))               # Generate random locs
zdf$Y <- 3 + sin(7 * zdf$x) + cos(9 * zdf$y)               # Latent process
zdf$z <- rnorm(m, mean = zdf$Y)                            # Simulate data
coordinates(zdf) = ~x+y                                    # Turn into sp object

## Construct BAUs and basis functions
BAUs <- auto_BAUs(manifold = plane(), data = zdf,
                  nonconvex_hull = FALSE, cellsize = c(0.03, 0.03), type="grid")
BAUs$fs <- 1 # scalar fine-scale covariance matrix
basis <- auto_basis(manifold =  plane(), data = zdf, nres = 2)

## Construct the SRE model
S <- SRE(f = z ~ 1, list(zdf), basis = basis, BAUs = BAUs)

## Fit with 2 EM iterations so to take as little time as possible
S <- SRE.fit(S, n_EM = 2, tol = 0.01, print_lik = TRUE)

## Check fit info, final log-likelihood, and estimated regression coefficients
info_fit(S)
logLik(S)
coef(S)

## Predict over BAUs
pred <- predict(S)

## Plot
\dontrun{
plotlist <- plot(S, pred)
ggpubr::ggarrange(plotlist = plotlist, nrow = 1, align = "hv", legend = "top")}
}
\references{
Zammit-Mangion, A. and Cressie, N. (2021). FRK: An R package for spatial and spatio-temporal prediction with large datasets. Journal of Statistical Software, 98(4), 1-48. doi:10.18637/jss.v098.i04.

Sainsbury-Dale, M. and Zammit-Mangion, A. and Cressie, N. (2023) Modelling Big, Heterogeneous, Non-Gaussian Spatial and Spatio-Temporal Data using FRK, arXiv:2110.02507
}
\seealso{
\code{\link{SRE-class}} for details on the SRE object internals,
\code{\link{auto_basis}} for automatically constructing basis functions, and
\code{\link{auto_BAUs}} for automatically constructing BAUs.
}
